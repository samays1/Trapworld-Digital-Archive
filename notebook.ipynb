{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius as genius\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect Genius.com API credentials and select artist\n",
    "geniusCreds = \"Jw2VCOyiGXdDET_ZIY0ZllMd0UkoYOEkUB_1dBYMvd4yZx3fJk8DnJsZ0MW71qft\"\n",
    "api = genius.Genius(geniusCreds)\n",
    "artist_name = \"migos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by migos...\n",
      "\n",
      "Changing artist name to 'Migos'\n",
      "Song 1: \"Bad and Boujee\"\n",
      "Song 2: \"Versace (Remix)\"\n",
      "Song 3: \"T-Shirt\"\n",
      "Song 4: \"Slippery\"\n",
      "Song 5: \"Walk It Talk It\"\n",
      "Song 6: \"Stir Fry\"\n",
      "Song 7: \"Kelly Price\"\n",
      "Song 8: \"Narcos\"\n",
      "Song 9: \"Get Right Witcha\"\n",
      "Song 10: \"Fight Night\"\n",
      "Song 11: \"Handsome and Wealthy\"\n",
      "Song 12: \"Notice Me\"\n",
      "Song 13: \"Call Casting\"\n",
      "Song 14: \"Deadz\"\n",
      "Song 15: \"Cocoon\"\n",
      "Song 16: \"Hannah Montana\"\n",
      "Song 17: \"Freak No More\"\n",
      "Song 18: \"BBO (Bad Bitches Only)\"\n",
      "Song 19: \"Bando\"\n",
      "Song 20: \"China Town\"\n",
      "Song 21: \"What the Price\"\n",
      "Song 22: \"Gang Gang\"\n",
      "Song 23: \"Culture\"\n",
      "Song 24: \"Pipe It Up\"\n",
      "Song 25: \"White Sand\"\n",
      "Song 26: \"Wishy Washy\"\n",
      "Song 27: \"Look at My Dab\"\n",
      "Song 28: \"Brown Paper Bag\"\n",
      "Song 29: \"Commando\"\n",
      "Song 30: \"Cross the Country\"\n",
      "Song 31: \"Versace\"\n",
      "Song 32: \"Dab of Ranch\"\n",
      "Song 33: \"Antidope\"\n",
      "Song 34: \"All Ass\"\n",
      "Song 35: \"Big on Big\"\n",
      "Song 36: \"Supastars\"\n",
      "Song 37: \"One Time\"\n",
      "Song 38: \"Out Yo Way\"\n"
     ]
    }
   ],
   "source": [
    "artist = api.search_artist(artist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote `Lyrics_LilUziVert.json`\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "artist.save_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Lyrics_TravisScott.json') as json_data:\n",
    "    data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs, albums, lyrics = [], [], []\n",
    "for song in data.get('songs'):\n",
    "    songs.append(song.get('full_title'))\n",
    "    if song.get('album') is not None:\n",
    "        albums.append(song.get('album').get('name'))\n",
    "    else: albums.append('Single')\n",
    "    song_lyrics = song.get('lyrics')\n",
    "    #remove identifiers like chorus, verse, etc\n",
    "    song_lyrics = re.sub(r'[\\(\\[].*?[\\)\\]]', '', song_lyrics)\n",
    "    #remove empty lines\n",
    "    song_lyrics = os.linesep.join([s for s in song_lyrics.splitlines() if s]) \n",
    "    lyrics.append(song_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.DataFrame({'song':songs, 'album':albums, 'lyrics':lyrics})\n",
    "corpus.to_csv('travis_scott.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatizer.lemmatize(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['contents'] = corpus['lyrics'].map(preprocess)\n",
    "corpus['lyrics'] = [' '.join(map(str, l)) for l in corpus['contents']]\n",
    "lda_songs = corpus[['song', 'contents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "def custom_colours(*args, **kwargs):\n",
    "    return \"#D61347\"\n",
    "cloud = WordCloud(background_color = \"#F5EFE0\", color_func = custom_colours, max_words = 250, contour_width = 5, width = 750, height = 500, random_state = 5)\n",
    "cloud.generate(\"\".join(list(corpus[\"lyrics\"].values)))\n",
    "#plt.imshow(cloud.recolor(color_func=random_color_func, random_state=3),interpolation=\"bilinear\")\n",
    "cloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = lda_songs.values   ## this cell is for putting all the files in a dictionary shape.\n",
    "file_dictionary = {}\n",
    "for i in file:\n",
    "    file_dictionary[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_files = []\n",
    "for key in file_dictionary:\n",
    "    processed_files.append(file_dictionary[key])\n",
    "dictionary = gensim.corpora.Dictionary(processed_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_files]\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_number = 10\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=topic_number, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.show_topics(num_topics=10, num_words=5, log=False, formatted=True): ## change num_words to see number of words you want to see in a topic\n",
    "    print('Topic: {} \\nWords: {}'.format(idx+1, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('travis_scott.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
